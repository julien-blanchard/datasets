{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Programming for analytics: CA 1**\n",
    "\n",
    "*   **Module owner**: Paul Laird\n",
    "\n",
    "*   **Module code**: B9BA100\n",
    "\n",
    "*   **Submitted by**: Julien Blanchard\n",
    "\n",
    "*   **Student number**: 10564273\n",
    "\n",
    "*   **Direct link (my GitHub page)**: [link](https://github.com/julien-blanchard/dbs)\n",
    "\n",
    "*   **References**: I have based myself on the following three books for this CA, and would highly recommend them to anyone interested in Python and Data science / Data analytics ([picture here](https://drive.google.com/file/d/1BYaz3KQtj1kYtOGESvXtmkyh2dx-YSKB/view?usp=sharing)):\n",
    "\n",
    "> [Data Science from Scratch](https://www.amazon.co.uk/Data-Science-Scratch-Principles-Python-ebook/dp/B07QPC8RZX/ref=sr_1_6?dchild=1&keywords=python+for+data+science&qid=1605271670&sr=8-6) by Joel Grus\n",
    "\n",
    "> [Python for Data Analysis](https://www.amazon.co.uk/Python-Data-Analysis-Wes-Mckinney/dp/1491957662/ref=sr_1_1?dchild=1&keywords=data+analysis+with+python&qid=1606428279&sr=8-1) by Wes McKinney (the creator of Pandas)\n",
    "\n",
    "> [Python Automation Cookbook](https://www.amazon.co.uk/Python-Automation-Cookbook-automation-processing-ebook/dp/B088NBRT6Z/ref=sr_1_3?dchild=1&keywords=automation+python&qid=1606428364&sr=8-3) by Jaime Buelta\n",
    "\n",
    "*   **Python syntax and conventions**: All the variables in this Colab will be written following the same naming convention: \"*my_variablename*\". Whenever possible, I'll be defining functions. All these functions will be written following the same naming convention: \"*make_actionname*\".\n",
    "\n",
    "\n",
    "*   **Table of contents**\n",
    "\n",
    "> 1) Extra work: creating our own txt files with Python\n",
    "\n",
    "> 2) CA question 1\n",
    "\n",
    "> 3) CA question 2\n",
    "\n",
    "> 4) Extra work: some very basic data analysis\n",
    "\n",
    "> 5) Extra work: some very basic email automation workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Creating 3 txt files using Random and Names\n",
    "\n",
    "To complete this CA, Paul has asked us to come up with three distinct .txt files:\n",
    "\n",
    "*   Employees.txt, which contains one line for each employee with the following information, separated by tab characters (\\t):\n",
    "\n",
    "*surname | first Name | PPSNumber | standard hours | HourlyRate | OvertimeRate | taxcredit | standardband*\n",
    "\n",
    "*   Hours.txt contains the following:\n",
    "\n",
    "*dd/mm/yyyy | staffID | hours_worked*\n",
    "\n",
    "*   Taxrates.txt contains the following information (%):\n",
    "\n",
    "*standardrate | higherrate*\n",
    "\n",
    "But rather than creating our employees / hours / rates .txt files manually, why don't we get Python to randomly generate everything for us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to install the Names library first\n",
    "# !pip install names\n",
    "\n",
    "# these are the libraries we will be working with\n",
    "import names\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Txt file 1: employees.txt\n",
    "\n",
    "Using the Random and Names library, we're going to create a dataframe that contains all the informations required for the employees.txt file, then remove its header and save the file locally. To be fair, I had never heard of the [Names](https://pypi.org/project/names/) library before. It's actually pretty straightforward!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Robert Bowie\n",
      "Staff ID: 4552R\n",
      "PPS: 4849661G\n",
      "Hourly wage: 14.64\n"
     ]
    }
   ],
   "source": [
    "# let's try and see how our names generator works\n",
    "my_rand_name = names.get_full_name()\n",
    "\n",
    "# according to the official documentation. Random can't generate letters. \n",
    "# But we need a letter for our PPS number! Let's be clever :)\n",
    "# We're using the String library, which has a function that list all letters in the alphabet. \n",
    "my_alphabet = list(string.ascii_uppercase)\n",
    "\n",
    "# we can now randomly pick any letter from the alphabet\n",
    "my_rand_letter = random.choice(my_alphabet)\n",
    "\n",
    "# now, onto our random employee IDs\n",
    "my_rand_id = str(random.randint(1000,9999)) + random.choice(my_alphabet)\n",
    "\n",
    "# for the hourly salary, any float between 12.0 and 20.0 will do\n",
    "my_rand_salary = round(random.uniform(12, 20), 2)\n",
    "\n",
    "# finally, let's print everything\n",
    "print('Name:', names.get_full_name())\n",
    "print('Staff ID:', str(random.randint(1000,9999)) + random.choice(my_alphabet))\n",
    "print('PPS:', str(random.randint(1000000,9999999)) + random.choice(my_alphabet))\n",
    "print('Hourly wage:', round(random.uniform(12, 20), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We can now create a simple function that will generate lists, add dictionary keys to these lists, and pass\n",
    "the whole thing into a Pandas dataframe. As an argument for our function, I have chosen to use the number\n",
    "of employees that we want to create.\n",
    "I'm setting 8 as the number of hours as this is the standard daily work hour volume in Ireland\n",
    "\"\"\"\n",
    "def make_employeesdataframe(howmany):\n",
    "    my_employees, my_id, my_hours, my_salary, my_pps = [],[],[],[],[]\n",
    "    for r in range(howmany):\n",
    "        my_employees.append( names.get_full_name() )\n",
    "    for r in range(howmany):\n",
    "        my_id.append( str(random.randint(1000,9999)) + random.choice(my_alphabet) )\n",
    "    for r in range(howmany):\n",
    "        my_hours.append( str(8) )\n",
    "    for r in range(howmany):\n",
    "        my_salary.append( round(random.uniform(12, 30), 2) )\n",
    "    for r in range(howmany):\n",
    "        my_pps.append( str(random.randint(1000000,9999999)) + random.choice(my_alphabet) )\n",
    "    # when creating a dataframe, the best approach is to use a dictionary, as the keys become the headers\n",
    "    my_columns = {'name': my_employees, 'staff_id': my_id, 'pps': my_pps, 'hours': my_hours, 'hourly_rate': my_salary}\n",
    "    df = pd.DataFrame(my_columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>staff_id</th>\n",
       "      <th>pps</th>\n",
       "      <th>hours</th>\n",
       "      <th>hourly_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miguel Guinasso</td>\n",
       "      <td>5923I</td>\n",
       "      <td>1116396C</td>\n",
       "      <td>8</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shavonda Creveling</td>\n",
       "      <td>7760M</td>\n",
       "      <td>2371118V</td>\n",
       "      <td>8</td>\n",
       "      <td>15.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Byron Rivera</td>\n",
       "      <td>7338D</td>\n",
       "      <td>4220484L</td>\n",
       "      <td>8</td>\n",
       "      <td>26.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enrique Bowling</td>\n",
       "      <td>7561Q</td>\n",
       "      <td>8416651O</td>\n",
       "      <td>8</td>\n",
       "      <td>29.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tracey Gilliard</td>\n",
       "      <td>9249J</td>\n",
       "      <td>9502450O</td>\n",
       "      <td>8</td>\n",
       "      <td>15.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name staff_id       pps hours  hourly_rate\n",
       "0     Miguel Guinasso    5923I  1116396C     8        14.00\n",
       "1  Shavonda Creveling    7760M  2371118V     8        15.23\n",
       "2        Byron Rivera    7338D  4220484L     8        26.92\n",
       "3     Enrique Bowling    7561Q  8416651O     8        29.69\n",
       "4     Tracey Gilliard    9249J  9502450O     8        15.08"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating data for 50 employees\n",
    "df_emp = make_employeesdataframe(51)\n",
    "\n",
    "# making sure it worked\n",
    "df_emp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>staff_id</th>\n",
       "      <th>pps</th>\n",
       "      <th>hours</th>\n",
       "      <th>hourly_rate</th>\n",
       "      <th>overtime_rate</th>\n",
       "      <th>tax_credit</th>\n",
       "      <th>standard_band</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miguel</td>\n",
       "      <td>Guinasso</td>\n",
       "      <td>5923I</td>\n",
       "      <td>1116396C</td>\n",
       "      <td>8</td>\n",
       "      <td>14.00</td>\n",
       "      <td>18.20</td>\n",
       "      <td>1.400</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Joe</td>\n",
       "      <td>Vargas</td>\n",
       "      <td>8831S</td>\n",
       "      <td>8788309K</td>\n",
       "      <td>8</td>\n",
       "      <td>29.59</td>\n",
       "      <td>38.47</td>\n",
       "      <td>2.959</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Noel</td>\n",
       "      <td>Heflin</td>\n",
       "      <td>2057C</td>\n",
       "      <td>8182053J</td>\n",
       "      <td>8</td>\n",
       "      <td>13.47</td>\n",
       "      <td>17.51</td>\n",
       "      <td>1.347</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_name last_name staff_id       pps hours  hourly_rate  overtime_rate  \\\n",
       "0      Miguel  Guinasso    5923I  1116396C     8        14.00          18.20   \n",
       "20        Joe    Vargas    8831S  8788309K     8        29.59          38.47   \n",
       "29       Noel    Heflin    2057C  8182053J     8        13.47          17.51   \n",
       "\n",
       "    tax_credit  standard_band  \n",
       "0        1.400             20  \n",
       "20       2.959             20  \n",
       "29       1.347             20  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before we save our dataframe into a txt file, we have to split our name serie into first name and last name\n",
    "df_emp['first_name'] = df_emp['name'].apply(lambda x: x.split(' ')[0])\n",
    "\n",
    "# same for our last name, this time in second position, so [1]\n",
    "df_emp['last_name'] = df_emp['name'].apply(lambda x: x.split(' ')[1])\n",
    "\n",
    "# we can now drop our old 'name' serie, using axis=1\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html\n",
    "df_emp = df_emp.drop(['name'], axis=1)\n",
    "\n",
    "# and now onto our overtime salary. Let's be generous: it will be +30% of our base hourly income\n",
    "df_emp['overtime_rate'] = df_emp['hourly_rate'].apply(lambda x: x * 1.3)\n",
    "df_emp['overtime_rate'] = df_emp['overtime_rate'].apply(lambda x: round(x, 2))\n",
    "\n",
    "# to be honest, I don't understand this tax credit / band stuff\n",
    "# so I'll just base myself on the following link, sorry if it makes zero sense\n",
    "# https://www.irishjobs.ie/careeradvice/understanding-your-payslip/\n",
    "\n",
    "# they say that the tax credit is a % of your income. I'll go for 10%\n",
    "df_emp['tax_credit'] = df_emp['hourly_rate'].apply(lambda x: (x /100) * 10 )\n",
    "# standard band is the tax bracket, right? Above this, employees are taxed more. We'll set it at 20E/h\n",
    "df_emp['standard_band'] = 20\n",
    "\n",
    "# last thing, Paul wants the txt file to be in a specific order\n",
    "my_columns = ['first_name', 'last_name', 'staff_id', 'pps', 'hours', 'hourly_rate', 'overtime_rate', 'tax_credit', 'standard_band']\n",
    "df_emp = df_emp.reindex(columns=my_columns)\n",
    "\n",
    "# showing our cleaned dataframe\n",
    "df_emp.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "And finally, saving the df as a txt file. I struggled a bit for this, but found help here:\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_string.html\n",
    "# https://stackoverflow.com/questions/51829923/write-a-pandas-dataframe-to-a-txt-file\n",
    "\n",
    "Something quite interesting: when using df.to_string I got some weird spacing issues, and my txt file\n",
    "would end up completely messed up. It seems that the best solution is to stick to df.to_csv and most \n",
    "importantly to keep either header or the index (which I had originally removed)\n",
    "\"\"\"\n",
    "\n",
    "df_emp.to_csv('employees.txt', header=True, index=False, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text file 2: hours.txt\n",
    "\n",
    "This is going to be much more straightforward. We're going to use Pandas' date_range() function, and then convert the datetime series to Y-M-D format, as date_range() by default adds hours (0), minutes (0), and seconds (0). The cool thing here is, we can generate a dataframe that is within any time range that we want to, as we can set up our starting and ending dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>staff_id</th>\n",
       "      <th>actual_worked_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>5923I</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>7760M</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>7338D</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>7561Q</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>9249J</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>7245P</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>1483F</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>9238F</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>3129B</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>8779Y</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>7389J</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>3148K</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>1619N</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>6162U</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>3302M</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>8335N</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>2941L</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>3670C</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>7132T</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>3306M</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date staff_id  actual_worked_hours\n",
       "0   2020-06-01    5923I                    8\n",
       "1   2020-06-01    7760M                   10\n",
       "2   2020-06-01    7338D                    9\n",
       "3   2020-06-01    7561Q                   10\n",
       "4   2020-06-01    9249J                    6\n",
       "5   2020-06-01    7245P                   11\n",
       "6   2020-06-01    1483F                    8\n",
       "7   2020-06-01    9238F                   10\n",
       "8   2020-06-01    3129B                    8\n",
       "9   2020-06-01    8779Y                    9\n",
       "10  2020-06-01    7389J                    9\n",
       "11  2020-06-01    3148K                    6\n",
       "12  2020-06-01    1619N                    6\n",
       "13  2020-06-01    6162U                    7\n",
       "14  2020-06-01    3302M                    9\n",
       "15  2020-06-01    8335N                    4\n",
       "16  2020-06-01    2941L                   10\n",
       "17  2020-06-01    3670C                    8\n",
       "18  2020-06-01    7132T                    9\n",
       "19  2020-06-01    3306M                   10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Defining a very simple function that creates a Pandas dataframe.\n",
    "Setting the default daily worked hours to 8\n",
    "Paul asked us to add in a PPS column, so for each day we have our employees covered\n",
    "Also adding in an \"actual worked hours\" column, randomized between 4 (half-day) and 12 (who works more\n",
    "than 12 hours in a day?). As you'll see below, we're using Numpy to generate these random integers\n",
    "\"\"\"\n",
    "\n",
    "def make_hoursdataframe(my_start, my_end):\n",
    "    my_dates = pd.date_range(start=my_start, end=my_end)\n",
    "    my_dict = {'date': my_dates}\n",
    "    df_hours = pd.DataFrame(my_dict)\n",
    "    df_hours['hours'] = 8\n",
    "    df_hours['date'] = df_hours.date.map(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    return df_hours\n",
    "\n",
    "# creating our dataframe, covering the second half of 2020\n",
    "df_hours = make_hoursdataframe('06/1/2020', '12/31/2020')\n",
    "\n",
    "# now we create a sub_df from our employees.txt, only using the PPS number and the 'expected hours'\n",
    "# fun fact, for 10 minutes I couldn't merge the df. It turns our that my df_emp['hours'] had become a string...\n",
    "df_pps = df_emp.filter(['staff_id', 'hours'])\n",
    "df_pps['hours'] = df_pps['hours'].astype(int)\n",
    "\n",
    "# LEFT JOIN on 'hours'\n",
    "df_hours = pd.merge(df_hours, df_pps)\n",
    "\n",
    "# finally, let's create a randomized 'actual work' column, based on:\n",
    "# https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.random.html\n",
    "df_hours['actual_worked_hours'] = np.random.randint(4, 12, df_hours.shape[0])\n",
    "\n",
    "# we no longer need the 'expected worked hours' as we've JOINed our dataframes\n",
    "df_hours = df_hours.drop(['hours'], axis=1)\n",
    "\n",
    "# showing our result\n",
    "df_hours.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same process as above, when we created our employees.txt file\n",
    "df_hours.to_csv('hours.txt', header=True, index=False, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text file 3: taxrates.txt\n",
    "\n",
    "Ok, I guess I'll have to be very honest here: I don't understand how this whole thing works. I guess I should actually be a little bit more aware of how the Irish tax system is structured, as I've been working in Ireland for over 10 years now.\n",
    "\n",
    "Anyway, I'll again use the official [citizen information website](https://www.citizensinformation.ie/en/money_and_tax/tax/income_tax_credits_and_reliefs/introduction_to_income_tax_credits_and_reliefs.html) as a source for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standard_rate</th>\n",
       "      <th>higher_rate</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   standard_rate  higher_rate  hours\n",
       "0             20           40      8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# third and last tine, let's create a dataframe building function!\n",
    "def make_taxdataframe(working_hours):\n",
    "    my_x, my_y = [20],[40]\n",
    "    my_dict = {'standard_rate': my_x, 'higher_rate': my_y, 'hours': working_hours}\n",
    "    df_tax = pd.DataFrame(my_dict)\n",
    "    return df_tax\n",
    "\n",
    "# creating this single row dataframe\n",
    "df_tax = make_taxdataframe([8])\n",
    "df_tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and that's our third and last txt file!\n",
    "# same process as above, when we created our employees.txt file\n",
    "df_tax.to_csv('taxrates.txt', header=True, index=False, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Getting our CA done\n",
    "Loading our freshly created txt files, and creating our payslips generating function!!!\n",
    "\n",
    "I have uploaded the files onto my GitHub, in case you want to run the code yourself (I have also shared these files with my classmates, so you might see these same files and names again):\n",
    "*   [employees txt](https://github.com/julien-blanchard/dbs/blob/main/employees.txt)\n",
    "*   [hours txt](https://github.com/julien-blanchard/dbs/blob/main/hours.txt)\n",
    "*   [taxrates txt](https://github.com/julien-blanchard/dbs/blob/main/taxrates.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing our main module, in case we're doing this second step independantly from the first one\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as weird as it seems, Pandas seems to read txt files through its read_csv function\n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html\n",
    "df_employees = pd.read_csv('employees.txt', sep=' ')\n",
    "# adding in a full name series, as several people might share the same first or last name, right?\n",
    "df_employees['full_name'] = df_employees.apply(lambda x:\n",
    "                                               x['first_name'] \n",
    "                                               + ' ' \n",
    "                                               + x['last_name'],\n",
    "                                               axis=1\n",
    "                                              )\n",
    "\n",
    "# next, let's load our hours.txt file. Same process, different dataframe name\n",
    "df_hours = pd.read_csv('hours.txt', sep=' ')\n",
    "\n",
    "# last but not least, here comes our taxrates.txt file\n",
    "df_tax = pd.read_csv('taxrates.txt', sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function description:\n",
    "\n",
    "**Foreword**:\n",
    "\n",
    "I have chosen to go for pure Pandas, instead of relying on a for loop approach. However, as I wouldn't want to be penalised for not using one concept over another, I have made sure to use a different approach for the bonus sections. My initial approach was to define the three following classes: Employee, Hours, Tax. It would have looked a bit like this:\n",
    "\n",
    "\n",
    "```\n",
    "class Employee:\n",
    "  def __init__(self, name):\n",
    "    self.by_name = df.loc[ (df['first_name'] == name)]\n",
    "  def get_filtered_df(self):\n",
    "    return self.by_name\n",
    "  def get_salary(self):\n",
    "    return self.by_name.at[0, 'hourly_rate']\n",
    "```\n",
    "\n",
    "**Chosen approach and basic requirement analysis**\n",
    "\n",
    "However, I changed my strategy after attending several classes for our *Requirement Analysis* module. Our teacher explained to us that as Business Analysts, our priority was our client, and that it was essential to focus on clarity and feasibility. This is why I changed my approach to using pure Pandas for this exercise, and here is why:\n",
    "\n",
    "*Problem recognition*:\n",
    "\n",
    "*   Identifying our **stakeholders**: Who is our \"client\" here? **Who are we building this payslip generator for**? Who are the people who will use it? What type of data structure are they familiar with? \n",
    "*   A quick search for \"**Payroll specialist**\" on Indeed ([link](https://ie.indeed.com/jobs?q=payroll+specialist&l=dublin)) shows that the most sought after skill for this type of role is **advanced Excel**. This most likely means that the people who work with payslips are accustomed to working with **tabular data**, which is exactly what Pandas provides.\n",
    "\n",
    "*Quality function deployment (QFD)*:\n",
    "\n",
    "*   Normal requirement: All our Payroll departments seems to want, is a simplified and automated way to generate individual payslips\n",
    "*   Expected requirement: Our Payroll department will most likely want to **store all this data** somewhere (probably on a monthly or quarterly basis). As we're merging several dataframes into a single dataframe (*df_temp*), all we would need to do is remove all the *print()* part from our function and replace these lines with *return df_temp*\n",
    "*   Expected requirement: Having a line by line, pure Pandas approach, will **allow non Python friendly people to make basic amendments** to the code. For this purpose, I have chunked the function you will see below into separate parts: dataframe handling, series handling, and printing. \n",
    "*   Exciting requirement: Using a Pandas dataframe will allow our Payroll department to use a library like [XLWings](https://www.xlwings.org/) and get familiar with Python. On a side note, [O'Reilly just published a book](https://www.oreilly.com/library/view/python-for-excel/9781492080992/) written by the person who created **XLWings**. I have personally never used this library, but the book's table of content seems to focus greatly on implementing Python in \"traditional\" and \"Excel oriented\" businesses like **banks or insurance companies**.\n",
    "*   Exciting requirement: We could then create very fancy looking **pdf files** using an open source framework such as [ReportLab](https://www.reportlab.com/opensource/). Coincidentally, the official documentation for ReportLab cites Pandas as one of its better supported data sources.\n",
    "*   Exciting requirement: Last but not least, using a Pandas dataframe makes it quite easy to automate an email workflow, using [Smtplib](https://docs.python.org/3/library/smtplib.html)\n",
    "\n",
    "**Methodology**:\n",
    "\n",
    "*   One important thing is: most people don't work weekends! I have found a function in Pandas that transforms a YY-MM-DD datetime serie into days of the week, and I have then removed Saturdays and Sundays from our dataframe. Funnily enough, I'm writing this line on a Saturday at 11am, I guess we can call this bad karma :)\n",
    "\n",
    "*   Another thing worth mentioning here: in Pandas, we don't need to specify the name of the columns that\n",
    "we are doing our JOIN on, unless they have different names. Here, all our txt files have a column named 'hours' and contain the exact same value: 8. No need to specify anything, Pandas does it for us. How cool is that? In SQL, we'd probably have wanted to come up with something along those lines:\n",
    "\n",
    "```\n",
    "WITH \n",
    "    t2 AS (SELECT col2 FROM whatever_table2),\n",
    "    t3 AS (SELECT col2 FROM whatever_table3)\n",
    "SELECT\n",
    "    t1.col1, t2.col2, t3.col2\n",
    "FROM t1\n",
    "LEFT JOIN t2 ON t1.pps_number = t2.pps_number\n",
    "LEFT JOIN t3 ON t1.pps_number = t3.pps_number\n",
    "```\n",
    "\n",
    "* My whole idea is to filter out our *Employees.txt* by **employee_name**, our *Hours.txt* by **start_day** and **end_day**, and then to merge / left join all dataframes together\n",
    "\n",
    "* What I do then is fairly straightforward: I **systematically create new series / columns**, based on the calculations I need. For instance you'll see a new serie for overtime hours, another one that transforms a date into a day or month string, etc...\n",
    "\n",
    "**What I could improve**:\n",
    "\n",
    "*   I only started learning Python about 3 years ago. Before that, and for many years, I was mainly an SQL user. The consequence of relaying for so many years on SQL and Excel is that I systematically tend to approach problems in terms of **tabular data**. It is quite difficult for me to approach data analysis and data visualisation issues in a more \"programming\" compliant mode.\n",
    "*   Because I merge dataframes and create new columns, we're a risk of gathering too much data and getting a **result overflow**. If we had more employees and a much larger timeframe, we could start running into some issues. To avoid that, we could break down our employees.txt by department (sales, HR, etc...) and our hours.txt by year.\n",
    "* I tend to to rely too much on **libraries / modules**, and not enough on \"pure python\". I think I would actually struggle more, but also learn a lot more, by not using Pandas. It wouldn't be suited for our Payroll department, but it would probably be an interesting exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_payslip(employee_name, start_day, end_day):\n",
    "    \"\"\"\n",
    "    What we are doing here:\n",
    "    # Filtering out our name and date range\n",
    "    # Merging our dataframes, one at a time\n",
    "    \"\"\"\n",
    "        # dataframes manipulation\n",
    "    df_refinedhours = df_hours.loc[ (df_hours['date'] >= start_day) & (df_hours['date'] <= end_day) ]\n",
    "    df_temp = df_employees.loc[ df_employees['full_name'] == employee_name]\n",
    "    df_temp = pd.merge(df_refinedhours, df_temp)\n",
    "    df_temp = pd.merge(df_temp, df_tax)\n",
    "    \"\"\"\n",
    "    What we are doing here:\n",
    "    # Before we start, I really dislike working with time series.\n",
    "    It always takes me quite a bit a trial and error before I manage to get to what I want\n",
    "    # So, we're converting our date serie to datetime format, then we extract the day of the week,\n",
    "    then we extract the month, and then we remove our Saturdays and Sundays\n",
    "    \"\"\"\n",
    "    # adding in some datetime series\n",
    "    df_temp['date'] = pd.to_datetime(df_temp['date'])\n",
    "    df_temp['day_name'] = df_temp['date'].dt.day_name()\n",
    "    df_temp['month_name'] = df_temp['date'].dt.month_name()\n",
    "    my_working_days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "    df_temp = df_temp.loc[ df_temp['day_name'].isin(my_working_days)]\n",
    "    \"\"\"\n",
    "    What we are doing here:\n",
    "    # We're using anonymous functions to create 2 new columns:\n",
    "    one that tells you how many overtime hours you have worked, and a second one\n",
    "    that shows how many regular hours you have worked\n",
    "    # on a side note, if you apply a lambda function on a whole dataframe and not on a single serie,\n",
    "    you HAVE to add axis=1 at the end, or you'll get an error code\n",
    "    \"\"\"\n",
    "    # dealing with overtime work\n",
    "    df_temp['overtime_worked'] = df_temp.apply(lambda x: \n",
    "                                               (x['actual_worked_hours'] - x['hours']) \n",
    "                                               if (x['actual_worked_hours'] > x['hours']) else 0, \n",
    "                                               axis=1\n",
    "                                              )\n",
    "    df_temp['regular_worked'] = df_temp.apply(lambda x: \n",
    "                                              x['actual_worked_hours'] \n",
    "                                              - x['overtime_worked'], \n",
    "                                              axis=1\n",
    "                                             )\n",
    "    df_temp['regular_paid'] = df_temp['regular_worked'] * df_temp['hourly_rate']\n",
    "    df_temp['overtime_paid'] = df_temp['overtime_worked'] * df_temp['overtime_rate']\n",
    "    \"\"\"\n",
    "    What we are doing here:\n",
    "    # Ok, this is my moment of shame. As you'll see further down, I'm relying a lot on\n",
    "    the at() function in Pandas to get my first row value. And for a good hour, whenever \n",
    "    I was changing the employee name, I would get no result. I then realised that my main\n",
    "    dataframe was keeping the original indexing for each employee... :( I solved the issue\n",
    "    by resetting the index!\n",
    "    # \n",
    "    \"\"\"\n",
    "     # resetting our index to avoid indexing errors\n",
    "    df_temp.reset_index(drop=True, inplace=True)\n",
    "    \"\"\"\n",
    "    What we are doing here:\n",
    "    # As mentioned above, I like SQL, and I went for a GROUP BY aggregation.\n",
    "    # I really recommend this amazing article https://www.shanelynn.ie/summarising-aggregation-and-grouping-data-in-python-pandas/\n",
    "    \"\"\"\n",
    "    # data aggregation\n",
    "    my_groupby_regular = df_temp.groupby(\n",
    "        ['full_name','month_name','hourly_rate'],\n",
    "        as_index=False).agg(\n",
    "        {'regular_worked':'sum', 'regular_paid':'sum'}\n",
    "    )\n",
    "    my_groupby_overtime = df_temp.groupby(\n",
    "        ['full_name','month_name', 'overtime_rate'],\n",
    "        as_index=False).agg(\n",
    "        {'overtime_worked':'sum', 'overtime_paid':'sum'}\n",
    "    )\n",
    "    \"\"\"\n",
    "    What we are doing here:\n",
    "    # Ok, I have one problem, and this problem isn't python related: I'm not sure I understand how the\n",
    "    different tax bands work. Here's how I understand things: taxes in Ireland work by bracket, or ladder.\n",
    "    Here we have a standard_band at 20 Euros per/hour. It means if person A and B make respectively\n",
    "    17 and 19 Euros per/hour, they are taxed the same. However, person C who makes 21 falls under the upper bracket\n",
    "    and is taxed more. Conveniently, Paul put the under 20E p/h bracket at 20% and the under 40E p/h bracket \n",
    "    at 40%. This is what you'll see in below for my_total_standardtaxes and my_total_highertaxes\n",
    "    # as for the rest, othing fancy I guess, but I didn't want my print() statements to be too long,\n",
    "    so I'm doing some final calculations here\n",
    "        \n",
    "    \"\"\"\n",
    "    # calculations\n",
    "    my_total_standardtaxes = (\n",
    "        (((sum(df_temp.hours) * df_temp.at[0, 'hourly_rate']) / 100) * df_temp.at[0, 'standard_rate']) \n",
    "        if (df_temp.at[0, 'hourly_rate'] <= df_temp.at[0, 'standard_rate']) \n",
    "        else 0\n",
    "        )\n",
    "    my_total_highertaxes =(\n",
    "        (((sum(df_temp.hours) * df_temp.at[0, 'hourly_rate']) / 100) * df_temp.at[0, 'higher_rate']) \n",
    "        if (df_temp.at[0, 'hourly_rate'] > df_temp.at[0, 'standard_rate']) \n",
    "        else 0\n",
    "        )    \n",
    "    my_taxcredit = round(df_temp.tax_credit.sum())\n",
    "    my_totalreductions = my_total_standardtaxes + my_total_highertaxes\n",
    "    my_grosspay = (df_temp.regular_paid.sum() + df_temp.overtime_paid.sum()).round(4)\n",
    "    my_startdate, my_enddate = df_temp.date.dt.date.min(), df_temp.date.dt.date.max()\n",
    "    \"\"\"\n",
    "    What we are doing here:\n",
    "    # Quick note: here, we could remove all the print() statements below and instead\n",
    "    put return df_temp. This way, our Payroll department would be able to store the payslips\n",
    "    #  As you can see I'm using df.at[] which conveniently returns any cell within our dataframe\n",
    "    following x and y locations. I'm always taking the first indexed position\n",
    "    \"\"\"\n",
    "    print('#########################################################################')\n",
    "    print('StaffID:', df_temp.at[0,'staff_id'])\n",
    "    print('Staff Name:', df_temp.at[0,'full_name'])\n",
    "    print('PPSN:', df_temp.at[0,'pps'])\n",
    "    print(f'Date covered: from {my_startdate} to {my_enddate}')\n",
    "    print('Number of days covered in this payslip:', df_temp.date.count())\n",
    "    print('###########################################################')\n",
    "    print('REGULAR')\n",
    "    print(my_groupby_regular)\n",
    "    print('OVERTIME')\n",
    "    print(my_groupby_overtime)\n",
    "    print('###########################################################')\n",
    "    print('Gross pay:\\t', my_grosspay)\n",
    "    print('###########################################################')\n",
    "    print(f'Standard band (if applies):\\t {my_total_standardtaxes}')\n",
    "    print(f'Higher rate (if applies):\\t {my_total_highertaxes}')\n",
    "    print('Total deductions:', my_totalreductions)\n",
    "    print('Tax credit:\\t', my_taxcredit)\n",
    "    print('Net deductions:\\t', (my_totalreductions - my_taxcredit).round(2))\n",
    "    print('Net pay:\\t', (my_grosspay + my_taxcredit - my_totalreductions).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample employee name 1:\n",
      " Danny Crews\n",
      "Sample employee name 2:\n",
      " Patrick Grove\n",
      "Sample employee name 3:\n",
      " Floy Pipkin\n",
      "Sample employee name 4:\n",
      " Alfredo Larsen\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Getting a few random employee mames, for our function below.\n",
    "Just run this cell as many times as needed, and pick whichever name you see below to create a payslip\n",
    "\"\"\"\n",
    "# using a simple for loop for this\n",
    "for x,y in enumerate(df_employees.full_name.sample(4)):\n",
    "    print('Sample employee name %d:\\n'%(x+1),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################################################\n",
      "StaffID: 3701H\n",
      "Staff Name: Danny Crews\n",
      "PPSN: 5147087I\n",
      "Date covered: from 2020-10-01 to 2020-11-02\n",
      "Number of days covered in this payslip: 23\n",
      "###########################################################\n",
      "REGULAR\n",
      "     full_name month_name  hourly_rate  regular_worked  regular_paid\n",
      "0  Danny Crews   November        26.99               8        215.92\n",
      "1  Danny Crews    October        26.99             141       3805.59\n",
      "OVERTIME\n",
      "     full_name month_name  overtime_rate  overtime_worked  overtime_paid\n",
      "0  Danny Crews   November          35.09                0            0.0\n",
      "1  Danny Crews    October          35.09               10          350.9\n",
      "###########################################################\n",
      "Gross pay:\t 4372.41\n",
      "###########################################################\n",
      "Standard band (if applies):\t 0\n",
      "Higher rate (if applies):\t 1986.464\n",
      "Total deductions: 1986.464\n",
      "Tax credit:\t 62.0\n",
      "Net deductions:\t 1924.46\n",
      "Net pay:\t 2447.95\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "There we go, we can now pass three arguments into our function: the employee's name, a start date,\n",
    "and an end date. This way, we can pick one day, one month, five weeks, etc...\n",
    "Of course, if we pick a Saturday or a Sunday, or if we input 'Xdfsfs' as an employee name, we'll\n",
    "get an error. So I'm adding an error exception message.\n",
    "\"\"\"\n",
    "# calling our previously created function\n",
    "try:\n",
    "    make_payslip('Danny Crews', '2020-10-01', '2020-11-02')\n",
    "except:\n",
    "    print('You have picked a wrong employee name, or a weekend day!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################################################\n",
      "StaffID: 5923I\n",
      "Staff Name: Miguel Guinasso\n",
      "PPSN: 1116396C\n",
      "Date covered: from 2020-10-01 to 2020-11-02\n",
      "Number of days covered in this payslip: 23\n",
      "###########################################################\n",
      "REGULAR\n",
      "         full_name month_name  hourly_rate  regular_worked  regular_paid\n",
      "0  Miguel Guinasso   November         14.0               8         112.0\n",
      "1  Miguel Guinasso    October         14.0             153        2142.0\n",
      "OVERTIME\n",
      "         full_name month_name  overtime_rate  overtime_worked  overtime_paid\n",
      "0  Miguel Guinasso   November           18.2                3           54.6\n",
      "1  Miguel Guinasso    October           18.2               19          345.8\n",
      "###########################################################\n",
      "Gross pay:\t 2654.4\n",
      "###########################################################\n",
      "Standard band (if applies):\t 450.8\n",
      "Higher rate (if applies):\t 160.16\n",
      "Total deductions: 610.96\n",
      "Tax credit:\t 32.0\n",
      "Net deductions:\t 578.96\n",
      "Net pay:\t 2075.44\n",
      "None\n",
      "#########################################################################\n",
      "StaffID: 7760M\n",
      "Staff Name: Shavonda Creveling\n",
      "PPSN: 2371118V\n",
      "Date covered: from 2020-10-01 to 2020-11-02\n",
      "Number of days covered in this payslip: 23\n",
      "###########################################################\n",
      "REGULAR\n",
      "            full_name month_name  hourly_rate  regular_worked  regular_paid\n",
      "0  Shavonda Creveling   November        15.23               8        121.84\n",
      "1  Shavonda Creveling    October        15.23             153       2330.19\n",
      "OVERTIME\n",
      "            full_name month_name  overtime_rate  overtime_worked  \\\n",
      "0  Shavonda Creveling   November           19.8                3   \n",
      "1  Shavonda Creveling    October           19.8               14   \n",
      "\n",
      "   overtime_paid  \n",
      "0           59.4  \n",
      "1          277.2  \n",
      "###########################################################\n",
      "Gross pay:\t 2788.63\n",
      "###########################################################\n",
      "Standard band (if applies):\t 490.41\n",
      "Higher rate (if applies):\t 134.64\n",
      "Total deductions: 625.05\n",
      "Tax credit:\t 35.0\n",
      "Net deductions:\t 590.05\n",
      "Net pay:\t 2198.58\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "And now if we want to apply this function to several employees\n",
    "I'm limiting it to 2 as I don't want to this ipynb file to double in size :)\n",
    "\"\"\"\n",
    "for employee in df_employees.full_name.to_list()[:2]:\n",
    "    print(make_payslip(employee, '2020-10-01', '2020-11-02'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, onto the second question of our CA!\n",
    "\n",
    "\"*Also output the weekly average gross pay for all workers each week, and the six-week rolling average gross pay for each employee with over six weeks' pay records*\"\n",
    "\n",
    "Ok, for this is the tricky part. Not in terms of using Python, but in terms of understanding the question. We actually had a 30 minute video conference call with my group, during which we all tried to explain how we thought we understood what Paul wanted here. My approach is the following:\n",
    "\n",
    "*   Paul wants first an ouput per week, and then a second output per employee over a 6 week period of time. it means that in both cases our function parameters have to be '**start_week**' and '**end_week**'. Indeed, if Paul wants two functions that very much do the same thing (as this is one single CA question), then we have to make sure our function parameters work for the two ouputs he wants.\n",
    "\n",
    "*   So, to achieve this, we're first goung to make some very slight amendments to the function we defined in question 1, but the overall logic, structure, and approach will remain the same.\n",
    "\n",
    "*   Then we're write add two additional arguments to our new function that should allow our Payroll department to be able to output some very useful data: the first one will be **GROUP BY** argument, allowing us to output data by week, or month, or employee name, etc... And the second one will define how we want our data **aggregated** in our GROUPed BY clause.\n",
    "\n",
    "Without further ado, let's jump over to the first part: \"*output the weekly average gross pay for all workers each week*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_number</th>\n",
       "      <th>aggregated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>172.076353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>172.167569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>166.494824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>167.343647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>168.300235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28</td>\n",
       "      <td>174.222235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>162.894784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>165.692824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31</td>\n",
       "      <td>166.548588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>163.939216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>33</td>\n",
       "      <td>172.682784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>34</td>\n",
       "      <td>169.991765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>35</td>\n",
       "      <td>166.090196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36</td>\n",
       "      <td>170.808157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>37</td>\n",
       "      <td>166.154039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>38</td>\n",
       "      <td>173.749922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>39</td>\n",
       "      <td>167.604235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40</td>\n",
       "      <td>171.005373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>41</td>\n",
       "      <td>164.702000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>42</td>\n",
       "      <td>165.852235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>43</td>\n",
       "      <td>168.313647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>44</td>\n",
       "      <td>161.905176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>45</td>\n",
       "      <td>172.434353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>46</td>\n",
       "      <td>165.483451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>47</td>\n",
       "      <td>171.072784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>48</td>\n",
       "      <td>168.849451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>49</td>\n",
       "      <td>164.050431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50</td>\n",
       "      <td>166.240824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>51</td>\n",
       "      <td>161.982706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>52</td>\n",
       "      <td>164.529686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>53</td>\n",
       "      <td>165.973922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    week_number  aggregated\n",
       "0            23  172.076353\n",
       "1            24  172.167569\n",
       "2            25  166.494824\n",
       "3            26  167.343647\n",
       "4            27  168.300235\n",
       "5            28  174.222235\n",
       "6            29  162.894784\n",
       "7            30  165.692824\n",
       "8            31  166.548588\n",
       "9            32  163.939216\n",
       "10           33  172.682784\n",
       "11           34  169.991765\n",
       "12           35  166.090196\n",
       "13           36  170.808157\n",
       "14           37  166.154039\n",
       "15           38  173.749922\n",
       "16           39  167.604235\n",
       "17           40  171.005373\n",
       "18           41  164.702000\n",
       "19           42  165.852235\n",
       "20           43  168.313647\n",
       "21           44  161.905176\n",
       "22           45  172.434353\n",
       "23           46  165.483451\n",
       "24           47  171.072784\n",
       "25           48  168.849451\n",
       "26           49  164.050431\n",
       "27           50  166.240824\n",
       "28           51  161.982706\n",
       "29           52  164.529686\n",
       "30           53  165.973922"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_weeklygrossaverage(start_week, end_week, group_by, aggregated):\n",
    "    \"\"\"\n",
    "    What we are doing here:\n",
    "    # merging our dataframes, the same way we did before\n",
    "    \"\"\"\n",
    "    df_temp = pd.merge(df_employees, df_hours)\n",
    "    df_temp = pd.merge(df_temp, df_tax)\n",
    "    \"\"\"\n",
    "    What are doing here:\n",
    "    # I found this super useful function in Pandas that return the number of the week for any given date.\n",
    "    For instance, as I'm finishing this we're on Saturday 28th October 2020 and therefore on week 48 this year\n",
    "    # One caveat though: depending on which version of Pandas you are using, you will either need to use:\n",
    "    .dt.week\n",
    "    OR\n",
    "    .dt.isocalendar().week\n",
    "    \"\"\"\n",
    "    # again, adding in some datetime series, with this time a week count\n",
    "    df_temp['date'] = pd.to_datetime(df_temp['date'])\n",
    "    df_temp['day_name'] = df_temp['date'].dt.day_name()\n",
    "    # adding a month column is an extra, but it'll make sense later\n",
    "    df_temp['month_name'] = df_temp['date'].dt.month_name()    \n",
    "    \n",
    "    # df_temp['week_number'] = df_temp['date'].dt.isocalendar().week\n",
    "    df_temp['week_number'] = df_temp['date'].dt.week\n",
    "    \n",
    "    # removing weekend days again\n",
    "    my_working_days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "    df_temp = df_temp.loc[ df_temp['day_name'].isin(my_working_days)]\n",
    "    df_temp = df_temp.loc[ (df_temp['week_number'] >= start_week) & (df_temp['week_number'] <= end_week) ]\n",
    "    \n",
    "    # Dealing with overtime / regular work the same way we did before\n",
    "    df_temp['overtime_worked'] = df_temp.apply(lambda x: \n",
    "                                               (x['actual_worked_hours'] - x['hours']) \n",
    "                                               if (x['actual_worked_hours'] > x['hours']) else 0, \n",
    "                                               axis=1\n",
    "                                              )\n",
    "    df_temp['regular_worked'] = df_temp.apply(lambda x: \n",
    "                                              x['actual_worked_hours'] \n",
    "                                              - x['overtime_worked'], \n",
    "                                              axis=1\n",
    "                                             )\n",
    "    \n",
    "    # for this last column, we are simply adding our 2 previously created series!\n",
    "    df_temp['total_gross_paid'] = df_temp.apply(lambda x:\n",
    "                                              (x['regular_worked'] * x['hourly_rate'])\n",
    "                                              + (x['overtime_worked'] * x['overtime_rate']),\n",
    "                                              axis=1\n",
    "                                              )\n",
    "    \n",
    "    # and finally, using once again a GROUP BY aggregation, I'm getting the average gross pay by week\n",
    "    df_weeklygrossaverage = df_temp.groupby(group_by, as_index=False).agg({'total_gross_paid': aggregated})\n",
    "    # this is completely optional, but I'm renaming the headers to match Paul's\n",
    "    # Please note that inplace=True means we're saving our changes to the dataframe\n",
    "    df_weeklygrossaverage.rename(columns={'total_gross_paid': 'aggregated'}, inplace=True)\n",
    "    return df_weeklygrossaverage\n",
    "\n",
    "# if you want all the weeks for the year simply pass 0,100 as arguments (though there are only 56 weeks per year)\n",
    "# as you can see, I'm aggregating by week number, and getting the mean\n",
    "# we're doing some sort of SELECT week_number, AVG(salary) FROM df GROUP BY week_number\n",
    "my_output = make_weeklygrossaverage(0, 100, 'week_number', 'mean')\n",
    "# the reason why we're not getting more weeks covered is that my hours.txt only has values from June to December\n",
    "my_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, onto the second part of this question: \"*and (also output) the six-week rolling average gross pay for each employee with over six weeks' pay records*\"\n",
    "\n",
    "What we're doing here is very simple: instead of doing a **GROUP BY** on weeks, we're doing a **GROUP BY** on employee names.\n",
    "\n",
    "In other words, we're going from this:\n",
    "```\n",
    "df_weeklygrossaverage = df_temp.groupby('week_number', as_index=False).agg({'total_gross_paid': 'mean'})\n",
    "```\n",
    "to this:\n",
    "```\n",
    "df_weeklygrossaverage = df_temp.groupby('full_name', as_index=False).agg({'total_gross_paid': 'mean'})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>aggregated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alfredo Larsen</td>\n",
       "      <td>178.482105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andree Esparza</td>\n",
       "      <td>202.234211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bernice Toan</td>\n",
       "      <td>180.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brigid Cahill</td>\n",
       "      <td>208.759474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Byron Rivera</td>\n",
       "      <td>185.608421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cedric King</td>\n",
       "      <td>176.508421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chelsey Morado</td>\n",
       "      <td>98.316316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cheryl Woodside</td>\n",
       "      <td>126.284211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Christian Norris</td>\n",
       "      <td>190.601053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cynthia Jones</td>\n",
       "      <td>151.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Danny Crews</td>\n",
       "      <td>214.785789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>David Folkers</td>\n",
       "      <td>216.677368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Denise Carpenter</td>\n",
       "      <td>226.008421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Denise Vick</td>\n",
       "      <td>184.048421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Doris Christin</td>\n",
       "      <td>163.231579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Doris Henson</td>\n",
       "      <td>115.555263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Edith Michael</td>\n",
       "      <td>209.346316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Enrique Bowling</td>\n",
       "      <td>203.768421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Floy Pipkin</td>\n",
       "      <td>159.037895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fred Truxler</td>\n",
       "      <td>219.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Guadalupe Spellman</td>\n",
       "      <td>108.643684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>James Swaim</td>\n",
       "      <td>180.178947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Jerry Palmer</td>\n",
       "      <td>234.156316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Jessica Savini</td>\n",
       "      <td>110.192632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Jessica Washington</td>\n",
       "      <td>200.469474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Joan Albertson</td>\n",
       "      <td>163.932632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Joe Vargas</td>\n",
       "      <td>183.458947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Julie Johnson</td>\n",
       "      <td>209.030526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Kayla Beltran</td>\n",
       "      <td>113.984211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Kevin Nichols</td>\n",
       "      <td>224.453158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Leslie Thomas</td>\n",
       "      <td>178.564737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Lucy Norman</td>\n",
       "      <td>147.214737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Marcela Fuoco</td>\n",
       "      <td>103.353684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Maria Pagan</td>\n",
       "      <td>151.743158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Miguel Guinasso</td>\n",
       "      <td>108.757895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Noah Hardcastle</td>\n",
       "      <td>176.528421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Noel Heflin</td>\n",
       "      <td>104.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Patrick Grove</td>\n",
       "      <td>195.962105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Prince Mcgurk</td>\n",
       "      <td>117.003158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Robert Gallegos</td>\n",
       "      <td>165.269474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ronald Brown</td>\n",
       "      <td>111.807368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ronald Owen</td>\n",
       "      <td>160.867368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Ruby Gipson</td>\n",
       "      <td>179.343158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ruth Francis</td>\n",
       "      <td>164.858947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Sally Seymour</td>\n",
       "      <td>158.156316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Shavonda Creveling</td>\n",
       "      <td>119.516316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Suzanne Rievley</td>\n",
       "      <td>116.365263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Thomas Carlson</td>\n",
       "      <td>245.325263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Tracey Gilliard</td>\n",
       "      <td>110.557895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wesley Barreto</td>\n",
       "      <td>103.858947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>William Chilcutt</td>\n",
       "      <td>136.575789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             full_name  aggregated\n",
       "0       Alfredo Larsen  178.482105\n",
       "1       Andree Esparza  202.234211\n",
       "2         Bernice Toan  180.910000\n",
       "3        Brigid Cahill  208.759474\n",
       "4         Byron Rivera  185.608421\n",
       "5          Cedric King  176.508421\n",
       "6       Chelsey Morado   98.316316\n",
       "7      Cheryl Woodside  126.284211\n",
       "8     Christian Norris  190.601053\n",
       "9        Cynthia Jones  151.052632\n",
       "10         Danny Crews  214.785789\n",
       "11       David Folkers  216.677368\n",
       "12    Denise Carpenter  226.008421\n",
       "13         Denise Vick  184.048421\n",
       "14      Doris Christin  163.231579\n",
       "15        Doris Henson  115.555263\n",
       "16       Edith Michael  209.346316\n",
       "17     Enrique Bowling  203.768421\n",
       "18         Floy Pipkin  159.037895\n",
       "19        Fred Truxler  219.315789\n",
       "20  Guadalupe Spellman  108.643684\n",
       "21         James Swaim  180.178947\n",
       "22        Jerry Palmer  234.156316\n",
       "23      Jessica Savini  110.192632\n",
       "24  Jessica Washington  200.469474\n",
       "25      Joan Albertson  163.932632\n",
       "26          Joe Vargas  183.458947\n",
       "27       Julie Johnson  209.030526\n",
       "28       Kayla Beltran  113.984211\n",
       "29       Kevin Nichols  224.453158\n",
       "30       Leslie Thomas  178.564737\n",
       "31         Lucy Norman  147.214737\n",
       "32       Marcela Fuoco  103.353684\n",
       "33         Maria Pagan  151.743158\n",
       "34     Miguel Guinasso  108.757895\n",
       "35     Noah Hardcastle  176.528421\n",
       "36         Noel Heflin  104.640000\n",
       "37       Patrick Grove  195.962105\n",
       "38       Prince Mcgurk  117.003158\n",
       "39     Robert Gallegos  165.269474\n",
       "40        Ronald Brown  111.807368\n",
       "41         Ronald Owen  160.867368\n",
       "42         Ruby Gipson  179.343158\n",
       "43        Ruth Francis  164.858947\n",
       "44       Sally Seymour  158.156316\n",
       "45  Shavonda Creveling  119.516316\n",
       "46     Suzanne Rievley  116.365263\n",
       "47      Thomas Carlson  245.325263\n",
       "48     Tracey Gilliard  110.557895\n",
       "49      Wesley Barreto  103.858947\n",
       "50    William Chilcutt  136.575789"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want all the weeks for the year simply pass 0,100 as arguments (though there are only 56 weeks per year)\n",
    "# and this time, we're aggregating by name\n",
    "my_output = make_weeklygrossaverage(50, 55, 'full_name', 'mean')\n",
    "# the reason why we're not getting more weeks covered is that my hours.txt only has values from June to December\n",
    "my_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_name</th>\n",
       "      <th>aggregated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>August</td>\n",
       "      <td>168.168114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>December</td>\n",
       "      <td>164.357067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>July</td>\n",
       "      <td>167.481390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>June</td>\n",
       "      <td>169.392424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>November</td>\n",
       "      <td>169.376265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>October</td>\n",
       "      <td>165.102959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>September</td>\n",
       "      <td>170.463556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  month_name  aggregated\n",
       "0     August  168.168114\n",
       "1   December  164.357067\n",
       "2       July  167.481390\n",
       "3       June  169.392424\n",
       "4   November  169.376265\n",
       "5    October  165.102959\n",
       "6  September  170.463556"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and now the cool thing, we can GROUP BY other stuff, like months!\n",
    "my_output = make_weeklygrossaverage(0, 100, 'month_name', 'mean')\n",
    "# the reason why we're not getting more weeks covered is that my hours.txt only has values from June to December\n",
    "my_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Extra 1: Having some fun with our dataframe\n",
    "\n",
    "What if we added some more series, like email addresses, age, role, etc..?\n",
    "\n",
    "To do so, we're going to create a fictional company named \"MScBizAnalyticsDBS\". What do we do? We sell paper, [of course](https://media4.giphy.com/media/5wWf7GR2nhgamhRnEuA/giphy.gif?cid=ecf05e47m5len2ftyls2jzt0l43y5msp07fskijbp23eftof&rid=giphy.gif)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll be needing some additional libraries for this\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing our df\n",
    "df = pd.read_csv('employees.txt', sep=' ')\n",
    "\n",
    "# first, let's create a randomized age column, based on:\n",
    "# https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.random.html\n",
    "df['age'] = np.random.randint(18, 61, df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Next, let's assign an email address to each employee\n",
    "\"\"\"\n",
    "\n",
    "df['full_name'] = df.apply(lambda x: x['first_name'] + ' ' + x['last_name'], axis=1)\n",
    "\n",
    "df['email'] = df.apply(lambda x: x['first_name'] + '.' + x['last_name'] + '@MScBizAnalyticsDBS.com', axis=1)\n",
    "df['email'] = df['email'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Managers in this company make more than: 27.1 EUR per hour\n"
     ]
    }
   ],
   "source": [
    "# and finally, let's try and see who's doing what, based on the salary column\n",
    "\n",
    "# let's define an upper tier salary base, combining the salary mean and standard deviation\n",
    "my_upper_tier = df.hourly_rate.mean() + df.hourly_rate.std()\n",
    "my_string = 'Managers in this company make more than: {x} EUR per hour'\n",
    "my_salary = round(df.hourly_rate.mean() + df.hourly_rate.std(), 2)\n",
    "print(my_string.format(x=my_salary))\n",
    "\n",
    "# we can also create a categorical serie, based on the simple calculation we just established\n",
    "def make_company_role(salary):\n",
    "    if salary >= my_upper_tier:\n",
    "        return 'manager'\n",
    "    else:\n",
    "        return 'employee'\n",
    "\n",
    "# applying this function to a new serie\n",
    "df['role'] = df['hourly_rate'].apply(make_company_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>staff_id</th>\n",
       "      <th>pps</th>\n",
       "      <th>hours</th>\n",
       "      <th>hourly_rate</th>\n",
       "      <th>overtime_rate</th>\n",
       "      <th>tax_credit</th>\n",
       "      <th>standard_band</th>\n",
       "      <th>age</th>\n",
       "      <th>full_name</th>\n",
       "      <th>email</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shavonda</td>\n",
       "      <td>Creveling</td>\n",
       "      <td>7760M</td>\n",
       "      <td>2371118V</td>\n",
       "      <td>8</td>\n",
       "      <td>15.23</td>\n",
       "      <td>19.8</td>\n",
       "      <td>1.523</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>Shavonda Creveling</td>\n",
       "      <td>shavonda.creveling@mscbizanalyticsdbs.com</td>\n",
       "      <td>employee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_name  last_name staff_id       pps  hours  hourly_rate  overtime_rate  \\\n",
       "1   Shavonda  Creveling    7760M  2371118V      8        15.23           19.8   \n",
       "\n",
       "   tax_credit  standard_band  age           full_name  \\\n",
       "1       1.523             20   21  Shavonda Creveling   \n",
       "\n",
       "                                       email      role  \n",
       "1  shavonda.creveling@mscbizanalyticsdbs.com  employee  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing what columns we now have\n",
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>hourly_rate</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>employee</td>\n",
       "      <td>20.219302</td>\n",
       "      <td>36.55814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>manager</td>\n",
       "      <td>29.363750</td>\n",
       "      <td>40.62500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       role  hourly_rate       age\n",
       "0  employee    20.219302  36.55814\n",
       "1   manager    29.363750  40.62500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can now get a grouped by overview of our company\n",
    "df_temp = df.groupby('role', as_index=False).agg( {'hourly_rate': 'mean', 'age': 'mean'} )\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-56ba34fdd08b4666b04d4bedd84dd762\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-56ba34fdd08b4666b04d4bedd84dd762\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-56ba34fdd08b4666b04d4bedd84dd762\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300, \"strokeWidth\": 0}, \"axis\": {\"grid\": false}, \"title\": {\"fontSize\": 20}}, \"hconcat\": [{\"mark\": \"bar\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"role\", \"scale\": {\"scheme\": \"lightgreyred\"}}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"full_name\"}, {\"type\": \"quantitative\", \"field\": \"hourly_rate\"}, {\"type\": \"quantitative\", \"field\": \"overtime_rate\"}], \"x\": {\"type\": \"quantitative\", \"bin\": true, \"field\": \"hourly_rate\"}, \"y\": {\"type\": \"quantitative\", \"aggregate\": \"count\"}}, \"height\": 250, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"Hourly rate distribution\", \"width\": 350}, {\"mark\": \"bar\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"role\", \"scale\": {\"scheme\": \"lightgreyred\"}}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"full_name\"}, {\"type\": \"quantitative\", \"field\": \"age\"}], \"x\": {\"type\": \"quantitative\", \"bin\": true, \"field\": \"age\"}, \"y\": {\"type\": \"quantitative\", \"aggregate\": \"count\"}}, \"height\": 250, \"selection\": {\"selector002\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"Age distribution\", \"width\": 350}], \"data\": {\"name\": \"data-4ea11ae465ef4252e6bf5d95ccf329ce\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-4ea11ae465ef4252e6bf5d95ccf329ce\": [{\"first_name\": \"Miguel\", \"last_name\": \"Guinasso\", \"staff_id\": \"5923I\", \"pps\": \"1116396C\", \"hours\": 8, \"hourly_rate\": 14.0, \"overtime_rate\": 18.2, \"tax_credit\": 1.4, \"standard_band\": 20, \"age\": 54, \"full_name\": \"Miguel Guinasso\", \"email\": \"miguel.guinasso@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Shavonda\", \"last_name\": \"Creveling\", \"staff_id\": \"7760M\", \"pps\": \"2371118V\", \"hours\": 8, \"hourly_rate\": 15.23, \"overtime_rate\": 19.8, \"tax_credit\": 1.5230000000000001, \"standard_band\": 20, \"age\": 21, \"full_name\": \"Shavonda Creveling\", \"email\": \"shavonda.creveling@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Byron\", \"last_name\": \"Rivera\", \"staff_id\": \"7338D\", \"pps\": \"4220484L\", \"hours\": 8, \"hourly_rate\": 26.92, \"overtime_rate\": 35.0, \"tax_credit\": 2.6919999999999997, \"standard_band\": 20, \"age\": 21, \"full_name\": \"Byron Rivera\", \"email\": \"byron.rivera@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Enrique\", \"last_name\": \"Bowling\", \"staff_id\": \"7561Q\", \"pps\": \"8416651O\", \"hours\": 8, \"hourly_rate\": 29.69, \"overtime_rate\": 38.6, \"tax_credit\": 2.969, \"standard_band\": 20, \"age\": 49, \"full_name\": \"Enrique Bowling\", \"email\": \"enrique.bowling@mscbizanalyticsdbs.com\", \"role\": \"manager\"}, {\"first_name\": \"Tracey\", \"last_name\": \"Gilliard\", \"staff_id\": \"9249J\", \"pps\": \"9502450O\", \"hours\": 8, \"hourly_rate\": 15.08, \"overtime_rate\": 19.6, \"tax_credit\": 1.508, \"standard_band\": 20, \"age\": 40, \"full_name\": \"Tracey Gilliard\", \"email\": \"tracey.gilliard@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Noah\", \"last_name\": \"Hardcastle\", \"staff_id\": \"7245P\", \"pps\": \"8911621R\", \"hours\": 8, \"hourly_rate\": 22.36, \"overtime_rate\": 29.07, \"tax_credit\": 2.236, \"standard_band\": 20, \"age\": 23, \"full_name\": \"Noah Hardcastle\", \"email\": \"noah.hardcastle@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Edith\", \"last_name\": \"Michael\", \"staff_id\": \"1483F\", \"pps\": \"7220781T\", \"hours\": 8, \"hourly_rate\": 28.27, \"overtime_rate\": 36.75, \"tax_credit\": 2.827, \"standard_band\": 20, \"age\": 45, \"full_name\": \"Edith Michael\", \"email\": \"edith.michael@mscbizanalyticsdbs.com\", \"role\": \"manager\"}, {\"first_name\": \"Sally\", \"last_name\": \"Seymour\", \"staff_id\": \"9238F\", \"pps\": \"3574536F\", \"hours\": 8, \"hourly_rate\": 23.83, \"overtime_rate\": 30.98, \"tax_credit\": 2.383, \"standard_band\": 20, \"age\": 21, \"full_name\": \"Sally Seymour\", \"email\": \"sally.seymour@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Marcela\", \"last_name\": \"Fuoco\", \"staff_id\": \"3129B\", \"pps\": \"8107111R\", \"hours\": 8, \"hourly_rate\": 14.99, \"overtime_rate\": 19.49, \"tax_credit\": 1.499, \"standard_band\": 20, \"age\": 20, \"full_name\": \"Marcela Fuoco\", \"email\": \"marcela.fuoco@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Denise\", \"last_name\": \"Vick\", \"staff_id\": \"8779Y\", \"pps\": \"1793614R\", \"hours\": 8, \"hourly_rate\": 24.54, \"overtime_rate\": 31.9, \"tax_credit\": 2.454, \"standard_band\": 20, \"age\": 20, \"full_name\": \"Denise Vick\", \"email\": \"denise.vick@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Brigid\", \"last_name\": \"Cahill\", \"staff_id\": \"7389J\", \"pps\": \"6871261F\", \"hours\": 8, \"hourly_rate\": 29.89, \"overtime_rate\": 38.86, \"tax_credit\": 2.989, \"standard_band\": 20, \"age\": 20, \"full_name\": \"Brigid Cahill\", \"email\": \"brigid.cahill@mscbizanalyticsdbs.com\", \"role\": \"manager\"}, {\"first_name\": \"Andree\", \"last_name\": \"Esparza\", \"staff_id\": \"3148K\", \"pps\": \"8264656P\", \"hours\": 8, \"hourly_rate\": 26.05, \"overtime_rate\": 33.87, \"tax_credit\": 2.605, \"standard_band\": 20, \"age\": 27, \"full_name\": \"Andree Esparza\", \"email\": \"andree.esparza@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Patrick\", \"last_name\": \"Grove\", \"staff_id\": \"1619N\", \"pps\": \"6734966Q\", \"hours\": 8, \"hourly_rate\": 26.22, \"overtime_rate\": 34.09, \"tax_credit\": 2.622, \"standard_band\": 20, \"age\": 24, \"full_name\": \"Patrick Grove\", \"email\": \"patrick.grove@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Ronald\", \"last_name\": \"Brown\", \"staff_id\": \"6162U\", \"pps\": \"9235705M\", \"hours\": 8, \"hourly_rate\": 13.93, \"overtime_rate\": 18.11, \"tax_credit\": 1.393, \"standard_band\": 20, \"age\": 55, \"full_name\": \"Ronald Brown\", \"email\": \"ronald.brown@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Joan\", \"last_name\": \"Albertson\", \"staff_id\": \"3302M\", \"pps\": \"8001426R\", \"hours\": 8, \"hourly_rate\": 21.69, \"overtime_rate\": 28.2, \"tax_credit\": 2.169, \"standard_band\": 20, \"age\": 52, \"full_name\": \"Joan Albertson\", \"email\": \"joan.albertson@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Kevin\", \"last_name\": \"Nichols\", \"staff_id\": \"8335N\", \"pps\": \"6855549A\", \"hours\": 8, \"hourly_rate\": 29.35, \"overtime_rate\": 38.16, \"tax_credit\": 2.9350000000000005, \"standard_band\": 20, \"age\": 52, \"full_name\": \"Kevin Nichols\", \"email\": \"kevin.nichols@mscbizanalyticsdbs.com\", \"role\": \"manager\"}, {\"first_name\": \"Alfredo\", \"last_name\": \"Larsen\", \"staff_id\": \"2941L\", \"pps\": \"9049572L\", \"hours\": 8, \"hourly_rate\": 22.02, \"overtime_rate\": 28.63, \"tax_credit\": 2.202, \"standard_band\": 20, \"age\": 21, \"full_name\": \"Alfredo Larsen\", \"email\": \"alfredo.larsen@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Lucy\", \"last_name\": \"Norman\", \"staff_id\": \"3670C\", \"pps\": \"7114274H\", \"hours\": 8, \"hourly_rate\": 18.95, \"overtime_rate\": 24.64, \"tax_credit\": 1.895, \"standard_band\": 20, \"age\": 51, \"full_name\": \"Lucy Norman\", \"email\": \"lucy.norman@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Jerry\", \"last_name\": \"Palmer\", \"staff_id\": \"7132T\", \"pps\": \"1523767U\", \"hours\": 8, \"hourly_rate\": 28.41, \"overtime_rate\": 36.93, \"tax_credit\": 2.841, \"standard_band\": 20, \"age\": 44, \"full_name\": \"Jerry Palmer\", \"email\": \"jerry.palmer@mscbizanalyticsdbs.com\", \"role\": \"manager\"}, {\"first_name\": \"Bernice\", \"last_name\": \"Toan\", \"staff_id\": \"3306M\", \"pps\": \"1062303H\", \"hours\": 8, \"hourly_rate\": 22.9, \"overtime_rate\": 29.77, \"tax_credit\": 2.29, \"standard_band\": 20, \"age\": 20, \"full_name\": \"Bernice Toan\", \"email\": \"bernice.toan@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Joe\", \"last_name\": \"Vargas\", \"staff_id\": \"8831S\", \"pps\": \"8788309K\", \"hours\": 8, \"hourly_rate\": 29.59, \"overtime_rate\": 38.47, \"tax_credit\": 2.9589999999999996, \"standard_band\": 20, \"age\": 59, \"full_name\": \"Joe Vargas\", \"email\": \"joe.vargas@mscbizanalyticsdbs.com\", \"role\": \"manager\"}, {\"first_name\": \"Kayla\", \"last_name\": \"Beltran\", \"staff_id\": \"2291W\", \"pps\": \"5260741P\", \"hours\": 8, \"hourly_rate\": 16.32, \"overtime_rate\": 21.22, \"tax_credit\": 1.632, \"standard_band\": 20, \"age\": 33, \"full_name\": \"Kayla Beltran\", \"email\": \"kayla.beltran@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Cheryl\", \"last_name\": \"Woodside\", \"staff_id\": \"8280D\", \"pps\": \"1855661G\", \"hours\": 8, \"hourly_rate\": 15.5, \"overtime_rate\": 20.15, \"tax_credit\": 1.55, \"standard_band\": 20, \"age\": 34, \"full_name\": \"Cheryl Woodside\", \"email\": \"cheryl.woodside@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Jessica\", \"last_name\": \"Washington\", \"staff_id\": \"1144N\", \"pps\": \"4131380P\", \"hours\": 8, \"hourly_rate\": 26.16, \"overtime_rate\": 34.01, \"tax_credit\": 2.616, \"standard_band\": 20, \"age\": 24, \"full_name\": \"Jessica Washington\", \"email\": \"jessica.washington@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Prince\", \"last_name\": \"Mcgurk\", \"staff_id\": \"7156F\", \"pps\": \"9196193F\", \"hours\": 8, \"hourly_rate\": 17.18, \"overtime_rate\": 22.33, \"tax_credit\": 1.7180000000000002, \"standard_band\": 20, \"age\": 34, \"full_name\": \"Prince Mcgurk\", \"email\": \"prince.mcgurk@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Thomas\", \"last_name\": \"Carlson\", \"staff_id\": \"9219M\", \"pps\": \"9298791W\", \"hours\": 8, \"hourly_rate\": 29.86, \"overtime_rate\": 38.82, \"tax_credit\": 2.986, \"standard_band\": 20, \"age\": 38, \"full_name\": \"Thomas Carlson\", \"email\": \"thomas.carlson@mscbizanalyticsdbs.com\", \"role\": \"manager\"}, {\"first_name\": \"David\", \"last_name\": \"Folkers\", \"staff_id\": \"9281R\", \"pps\": \"6475143J\", \"hours\": 8, \"hourly_rate\": 25.99, \"overtime_rate\": 33.79, \"tax_credit\": 2.599, \"standard_band\": 20, \"age\": 59, \"full_name\": \"David Folkers\", \"email\": \"david.folkers@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Cedric\", \"last_name\": \"King\", \"staff_id\": \"2824L\", \"pps\": \"6237981B\", \"hours\": 8, \"hourly_rate\": 25.14, \"overtime_rate\": 32.68, \"tax_credit\": 2.514, \"standard_band\": 20, \"age\": 45, \"full_name\": \"Cedric King\", \"email\": \"cedric.king@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Fred\", \"last_name\": \"Truxler\", \"staff_id\": \"5437A\", \"pps\": \"4323268X\", \"hours\": 8, \"hourly_rate\": 29.85, \"overtime_rate\": 38.8, \"tax_credit\": 2.985, \"standard_band\": 20, \"age\": 18, \"full_name\": \"Fred Truxler\", \"email\": \"fred.truxler@mscbizanalyticsdbs.com\", \"role\": \"manager\"}, {\"first_name\": \"Noel\", \"last_name\": \"Heflin\", \"staff_id\": \"2057C\", \"pps\": \"8182053J\", \"hours\": 8, \"hourly_rate\": 13.47, \"overtime_rate\": 17.51, \"tax_credit\": 1.3470000000000002, \"standard_band\": 20, \"age\": 37, \"full_name\": \"Noel Heflin\", \"email\": \"noel.heflin@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Leslie\", \"last_name\": \"Thomas\", \"staff_id\": \"9795I\", \"pps\": \"5919093M\", \"hours\": 8, \"hourly_rate\": 24.91, \"overtime_rate\": 32.38, \"tax_credit\": 2.491, \"standard_band\": 20, \"age\": 21, \"full_name\": \"Leslie Thomas\", \"email\": \"leslie.thomas@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"James\", \"last_name\": \"Swaim\", \"staff_id\": \"1447O\", \"pps\": \"7680069D\", \"hours\": 8, \"hourly_rate\": 23.94, \"overtime_rate\": 31.12, \"tax_credit\": 2.394, \"standard_band\": 20, \"age\": 43, \"full_name\": \"James Swaim\", \"email\": \"james.swaim@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Danny\", \"last_name\": \"Crews\", \"staff_id\": \"3701H\", \"pps\": \"5147087I\", \"hours\": 8, \"hourly_rate\": 26.99, \"overtime_rate\": 35.09, \"tax_credit\": 2.699, \"standard_band\": 20, \"age\": 46, \"full_name\": \"Danny Crews\", \"email\": \"danny.crews@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Denise\", \"last_name\": \"Carpenter\", \"staff_id\": \"4624B\", \"pps\": \"9704556K\", \"hours\": 8, \"hourly_rate\": 26.99, \"overtime_rate\": 35.09, \"tax_credit\": 2.699, \"standard_band\": 20, \"age\": 38, \"full_name\": \"Denise Carpenter\", \"email\": \"denise.carpenter@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Ruth\", \"last_name\": \"Francis\", \"staff_id\": \"9754D\", \"pps\": \"1784389P\", \"hours\": 8, \"hourly_rate\": 20.73, \"overtime_rate\": 26.95, \"tax_credit\": 2.073, \"standard_band\": 20, \"age\": 37, \"full_name\": \"Ruth Francis\", \"email\": \"ruth.francis@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Julie\", \"last_name\": \"Johnson\", \"staff_id\": \"2075P\", \"pps\": \"1701991V\", \"hours\": 8, \"hourly_rate\": 25.89, \"overtime_rate\": 33.66, \"tax_credit\": 2.5890000000000004, \"standard_band\": 20, \"age\": 33, \"full_name\": \"Julie Johnson\", \"email\": \"julie.johnson@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Doris\", \"last_name\": \"Christin\", \"staff_id\": \"5560S\", \"pps\": \"9240843Q\", \"hours\": 8, \"hourly_rate\": 19.58, \"overtime_rate\": 25.45, \"tax_credit\": 1.958, \"standard_band\": 20, \"age\": 52, \"full_name\": \"Doris Christin\", \"email\": \"doris.christin@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Floy\", \"last_name\": \"Pipkin\", \"staff_id\": \"5963X\", \"pps\": \"3180541V\", \"hours\": 8, \"hourly_rate\": 20.57, \"overtime_rate\": 26.74, \"tax_credit\": 2.057, \"standard_band\": 20, \"age\": 45, \"full_name\": \"Floy Pipkin\", \"email\": \"floy.pipkin@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Ruby\", \"last_name\": \"Gipson\", \"staff_id\": \"6018U\", \"pps\": \"5058660G\", \"hours\": 8, \"hourly_rate\": 22.9, \"overtime_rate\": 29.77, \"tax_credit\": 2.29, \"standard_band\": 20, \"age\": 37, \"full_name\": \"Ruby Gipson\", \"email\": \"ruby.gipson@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Christian\", \"last_name\": \"Norris\", \"staff_id\": \"2427D\", \"pps\": \"4090629U\", \"hours\": 8, \"hourly_rate\": 24.24, \"overtime_rate\": 31.51, \"tax_credit\": 2.424, \"standard_band\": 20, \"age\": 58, \"full_name\": \"Christian Norris\", \"email\": \"christian.norris@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Wesley\", \"last_name\": \"Barreto\", \"staff_id\": \"6501V\", \"pps\": \"4612700P\", \"hours\": 8, \"hourly_rate\": 12.94, \"overtime_rate\": 16.82, \"tax_credit\": 1.2939999999999998, \"standard_band\": 20, \"age\": 30, \"full_name\": \"Wesley Barreto\", \"email\": \"wesley.barreto@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Jessica\", \"last_name\": \"Savini\", \"staff_id\": \"4647C\", \"pps\": \"3022894C\", \"hours\": 8, \"hourly_rate\": 17.52, \"overtime_rate\": 22.78, \"tax_credit\": 1.7519999999999998, \"standard_band\": 20, \"age\": 22, \"full_name\": \"Jessica Savini\", \"email\": \"jessica.savini@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Ronald\", \"last_name\": \"Owen\", \"staff_id\": \"3221W\", \"pps\": \"5470821Y\", \"hours\": 8, \"hourly_rate\": 20.92, \"overtime_rate\": 27.2, \"tax_credit\": 2.092, \"standard_band\": 20, \"age\": 37, \"full_name\": \"Ronald Owen\", \"email\": \"ronald.owen@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Cynthia\", \"last_name\": \"Jones\", \"staff_id\": \"4155L\", \"pps\": \"8516356S\", \"hours\": 8, \"hourly_rate\": 20.07, \"overtime_rate\": 26.09, \"tax_credit\": 2.007, \"standard_band\": 20, \"age\": 47, \"full_name\": \"Cynthia Jones\", \"email\": \"cynthia.jones@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"William\", \"last_name\": \"Chilcutt\", \"staff_id\": \"3485Q\", \"pps\": \"7404789N\", \"hours\": 8, \"hourly_rate\": 15.68, \"overtime_rate\": 20.38, \"tax_credit\": 1.568, \"standard_band\": 20, \"age\": 23, \"full_name\": \"William Chilcutt\", \"email\": \"william.chilcutt@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Doris\", \"last_name\": \"Henson\", \"staff_id\": \"5713L\", \"pps\": \"1032379Y\", \"hours\": 8, \"hourly_rate\": 15.56, \"overtime_rate\": 20.23, \"tax_credit\": 1.556, \"standard_band\": 20, \"age\": 37, \"full_name\": \"Doris Henson\", \"email\": \"doris.henson@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Suzanne\", \"last_name\": \"Rievley\", \"staff_id\": \"4931F\", \"pps\": \"3507387D\", \"hours\": 8, \"hourly_rate\": 15.77, \"overtime_rate\": 20.5, \"tax_credit\": 1.577, \"standard_band\": 20, \"age\": 44, \"full_name\": \"Suzanne Rievley\", \"email\": \"suzanne.rievley@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Guadalupe\", \"last_name\": \"Spellman\", \"staff_id\": \"7566X\", \"pps\": \"6722775W\", \"hours\": 8, \"hourly_rate\": 14.09, \"overtime_rate\": 18.32, \"tax_credit\": 1.409, \"standard_band\": 20, \"age\": 54, \"full_name\": \"Guadalupe Spellman\", \"email\": \"guadalupe.spellman@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Robert\", \"last_name\": \"Gallegos\", \"staff_id\": \"1347O\", \"pps\": \"2916447F\", \"hours\": 8, \"hourly_rate\": 21.26, \"overtime_rate\": 27.64, \"tax_credit\": 2.1260000000000003, \"standard_band\": 20, \"age\": 35, \"full_name\": \"Robert Gallegos\", \"email\": \"robert.gallegos@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Maria\", \"last_name\": \"Pagan\", \"staff_id\": \"2558S\", \"pps\": \"1826220T\", \"hours\": 8, \"hourly_rate\": 17.72, \"overtime_rate\": 23.04, \"tax_credit\": 1.7719999999999998, \"standard_band\": 20, \"age\": 53, \"full_name\": \"Maria Pagan\", \"email\": \"maria.pagan@mscbizanalyticsdbs.com\", \"role\": \"employee\"}, {\"first_name\": \"Chelsey\", \"last_name\": \"Morado\", \"staff_id\": \"7249U\", \"pps\": \"8694698A\", \"hours\": 8, \"hourly_rate\": 12.69, \"overtime_rate\": 16.5, \"tax_credit\": 1.2690000000000001, \"standard_band\": 20, \"age\": 44, \"full_name\": \"Chelsey Morado\", \"email\": \"chelsey.morado@mscbizanalyticsdbs.com\", \"role\": \"employee\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ok, so for this part, I have to say that I'm a big fan of a visualisation library called Altair.\n",
    "It can output interactive charts, like Bokeh or Plotly, but is much easier to use.\n",
    "Simply put your mouse cursor over the charts below and you'll see some interactive data\n",
    "Over the past few months at work, I have tended to use Altair more frequently than Seaborn\n",
    "\"\"\"\n",
    "# creating a left chart forst\n",
    "my_leftchart = alt.Chart(df).mark_bar().encode( # we have selected df as our dataframe\n",
    "    x=alt.X('hourly_rate:Q', bin=True), # our X, in quantitative format\n",
    "    y=alt.Y('count()'),\n",
    "    color=alt.Color('role', scale=alt.Scale(scheme='lightgreyred')), # this works like 'hue' in Seaborn\n",
    "    tooltip = [alt.Tooltip('full_name'), # it's this part that determine which serie you want to make interactive\n",
    "               alt.Tooltip('hourly_rate'),\n",
    "               alt.Tooltip('overtime_rate')]\n",
    ").properties( # nothing crazy here, just our chart size and title\n",
    "    width=350,\n",
    "    height=250,\n",
    "    title='Hourly rate distribution'\n",
    ").interactive()\n",
    "\n",
    "my_rightchart = alt.Chart(df).mark_bar().encode(\n",
    "    x=alt.X('age:Q', bin=True),\n",
    "    y=alt.Y('count()'),\n",
    "    color=alt.Color('role', scale=alt.Scale(scheme='lightgreyred')),\n",
    "    tooltip = [alt.Tooltip('full_name'),\n",
    "               alt.Tooltip('age')]\n",
    ").properties(\n",
    "    width=350,\n",
    "    height=250,\n",
    "    title='Age distribution'\n",
    ").interactive()\n",
    "\n",
    "alt.hconcat(my_leftchart, my_rightchart).configure_axis( # concatenating our 2 charts\n",
    "    grid=False\n",
    ").configure_view(\n",
    "    strokeWidth=0\n",
    ").configure_title(\n",
    "fontSize=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what can we see from the two charts above?\n",
    "*   We have a rather strange salary distribution (left chart), as we can see that most of our employees are either on the lowest extreme of the salary range, or on the higher extreme of the salary range. Maybe we should consider offering a more balanced retribution approach?\n",
    "*   The bar chart on the right seems to indicate that most of our employees are between the age of 20 and 25, while most of our managers are betweem 45 and 50 years old. This should raise some questions: Why are our employees so young? Could this be related to the salary imbalance we saw on the other chart? This might indicate that we're good at hiring younger people, but maybe not at keeping them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Extra 2: Automating payslip emails\n",
    "\n",
    "For our last part, I won't go into anything too fancy. Ideally, we would want to remove all the print() lines from our CA function, and replace them with '*return df_temp*', which would then create a single dataframe per employee.\n",
    "\n",
    "We could then loop througn all our employees, and create an individual dataframe for each, or for some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import all the modules we will need for this exercise\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtplib import SMTP\n",
    "import smtplib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_payslip_email(sender, receiver, password, subject, payslip_df):\n",
    "    # account and message\n",
    "    my_sender_email = sender  # I created this address specifically for this project!\n",
    "    my_receiver_email = receiver  # Enter receiver address\n",
    "    my_password = password # Please open the password.txt file I have attached to my CA submission \n",
    "\n",
    "    # let's get started!\n",
    "    my_message = MIMEMultipart()\n",
    "    # Here we're defining our subject. Instead of 'Your' we could use an f string loop through our employees' name\n",
    "    my_message['Subject'] = subject\n",
    "    # That's pretty straightforward\n",
    "    my_message['From'] = my_sender_email\n",
    "    # more interesting: it's in list format! Which means we could again loop through our employees, add some conditions, etc..\n",
    "    my_recipients = [my_receiver_email] \n",
    "    # this part I'm not sure of, but it seems to work. I basically used the default setting from the official library \n",
    "    # documentation: https://docs.python.org/2.0/lib/SMTP-example.html\n",
    "    my_emaillist = [m.strip().split(',') for m in my_recipients]\n",
    "    # that's quite cool: we can add some HTML formatting and simply add our Pandas dataframe at the end!!\n",
    "    my_html = \"\"\"\\\n",
    "    <html>\n",
    "      <head></head>\n",
    "      <body>\n",
    "        {0}\n",
    "      </body>\n",
    "    </html>\n",
    "    \"\"\".format(payslip_df.to_html()) # here I have put df_temp as my payslip_df, but each payslip would be unique and generated through a loop\n",
    "    # we're going for hmtl, which is the default format\n",
    "    my_email = MIMEText(my_html, 'html')\n",
    "    # and finally, we attach the email\n",
    "    my_message.attach(my_email)\n",
    "    \"\"\"\n",
    "    So here I ran into some issues. Though I have activated the gMail account, it seems that because my\n",
    "    account is too recent and because I haven't sent enough emails, I'm in some sort of restricted accounts pool.\n",
    "\n",
    "    To bypass that, if you get an authentification error, follow these steps:\n",
    "    1. Confirm that recent logins really were from you on the [Google account security page](https://myaccount.google.com/security)\n",
    "    2. Unlock the account by [entering a captcha](http://www.google.com/accounts/DisplayUnlockCaptcha).\n",
    "\n",
    "    I found the solution here: https://help.pythonanywhere.com/pages/SMTPForFreeUsers\n",
    "\n",
    "    \"\"\"\n",
    "    # let's create an SMTP session. Port 587 is the official gMail port\n",
    "    # https://support.google.com/a/answer/176600?hl=en\n",
    "    my_session = smtplib.SMTP('smtp.gmail.com', 587) \n",
    "    # start TLS for security \n",
    "    my_session.starttls() \n",
    "    # Authentication \n",
    "    my_session.login(my_sender_email, my_password)\n",
    "    # sending the mail \n",
    "    send_payslip = my_session.sendmail(message['From'], my_emaillist , my_message.as_string()) \n",
    "    return send_payslip\n",
    "    \n",
    "make_payslip_email('dbsstudentproject2020@gmail.com','suzanne.rievley@mscbizanalyticsdbs.com','xxxxxxx','Your payslip',df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final words\n",
    "\n",
    "That's pretty much it! I hope you have enjoyed reading this ipnyb file as much as I gave enjoyed writing it.\n",
    "\n",
    "Thanks for your time!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
